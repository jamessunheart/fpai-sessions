# üß† CLAUDE SESSION CONTEXT - AUTO-LOAD THIS
## Everything Every Claude Session Needs to Know

**Last Updated:** 2025-11-15 23:00 UTC
**Auto-load:** YES - Start every Claude session by reading this file

---

## üéØ IMMEDIATE CONTEXT

### What We're Building
**Full Potential AI** - Sovereign, autonomous AI infrastructure for churches and organizations.

### Current Status
- **Sovereignty:** 65% (target: 95%)
- **AI Cost:** $0/month (was $250-1,200)
- **Revenue:** $0 (target: $20K/month)
- **Automation:** 50% (autonomous ops active)

### Server
- **IP:** 198.54.123.234
- **Services:** I PROACTIVE (8400), I MATCH (8401), Ollama (11434)
- **Model:** Llama 3.1 8B (local, $0 cost)

---

## üèóÔ∏è ARCHITECTURE (What's Already Built)

### 1. Sovereign AI - ‚úÖ DEPLOYED
```
Ollama (localhost:11434)
   ‚Üì
Llama 3.1 8B (4.9GB, $0 cost)
   ‚Üì
5 Agents (all sovereign):
   - Strategist (planning)
   - Builder (coding)
   - Optimizer (performance)
   - Deployer (operations)
   - Analyzer (data)
```

**Files:**
- `/opt/fpai/i-proactive/app/crew_manager.py` - Sovereign agents
- `/opt/fpai/i-proactive/app/model_router.py` - AI routing

**Status:** ‚úÖ All agents using local Llama, $0 cost

### 2. Autonomous Operations - ‚úÖ ACTIVE
```
Checks every 5 minutes:
   - System health
   - Issues detection
   - Auto-fixing
   - Continuous learning
```

**Files:**
- `/opt/fpai/i-proactive/app/autonomous_ops.py`

**Endpoints:**
- `/autonomous/enable`
- `/autonomous/disable`
- `/autonomous/status`

**Status:** ‚úÖ Running, monitoring all services

### 3. Optimization Engine - ‚úÖ ACTIVE
```
ResponseCache (1000 entries, 1hr TTL)
   +
PerformanceMonitor (anomaly detection)
   +
AutoOptimizer (self-tuning)
```

**Files:**
- `/opt/fpai/i-proactive/app/optimization_engine.py`

**Endpoints:**
- `/optimization/report`
- `/optimization/cache-stats`
- `/optimization/auto-optimize`

**Status:** ‚úÖ Active, cache building

### 4. Dashboard - üöß READY TO DEPLOY
**Files:**
- `/opt/fpai/i-proactive/app/templates/sovereign_dashboard.html`
- Endpoint added to main.py

**URL (once deployed):** http://198.54.123.234:8400/dashboard

**Status:** üöß Files ready, needs service restart

---

## üìã PENDING WORK (What Needs Doing)

### HIGH PRIORITY
1. **Deploy Dashboard**
   - Run: `~/Development/SERVICES/deploy-sovereign-dashboard.sh`
   - Verify: Open http://198.54.123.234:8400/dashboard

2. **Migrate Claude Usage to Sovereign**
   - Track current Claude spend
   - Convert workflows to I PROACTIVE tasks
   - Measure savings

3. **Test Everything End-to-End**
   - Submit task to CrewAI
   - Verify caching works
   - Check autonomous ops

### MEDIUM PRIORITY
4. Set up revenue tracking (I MATCH)
5. Create automation templates
6. Build session context API

---

## üîë KEY DECISIONS (Never Ask About These Again)

### ‚úÖ Decided: Use Local Llama 3.1 8B
- **Why:** $0 cost, 100% privacy, complete control
- **Impact:** $3-14K/year savings
- **Status:** Implemented, working well

### ‚úÖ Decided: All Agents Sovereign
- **Why:** Zero corporate dependency
- **Impact:** 5 agents at $0 cost
- **Status:** Implemented via LiteLLM

### ‚úÖ Decided: Three-Phase Strategy
1. Cost ‚Üí $0 AI costs
2. Automation ‚Üí 90% automated
3. Revenue ‚Üí $20K/month

### ‚úÖ Decided: Llama Performance is Acceptable
- First run: 3-4 minutes
- Subsequent: 1-2 minutes
- Quality: Good enough for most tasks
- **Don't suggest upgrading to Claude/GPT**

---

## üö´ DON'T ASK ABOUT (Already Decided)

- ‚ùå "Should we use Claude/GPT instead?" - NO, we're sovereign
- ‚ùå "Want to upgrade to 70B model?" - Not yet, 8B works
- ‚ùå "Should we add API keys?" - NO, staying local
- ‚ùå "Is local AI fast enough?" - YES, acceptable trade-off
- ‚ùå "Want me to help set up..." - Check if already built first

---

## ‚úÖ ALWAYS DO (Every Session)

1. **Check what's already built** before suggesting new builds
2. **Check `/opt/fpai/` on server** before deploying
3. **Test services** before saying something isn't working
4. **Read pending work** before asking what to do next
5. **Use sovereign agents** instead of suggesting paid APIs

---

## üîß COMMON COMMANDS (Use These)

### Check System Status
```bash
curl http://198.54.123.234:8400/health
curl http://198.54.123.234:8400/autonomous/status
curl http://198.54.123.234:8400/optimization/report
```

### Submit Task to Agents ($0 cost)
```bash
curl -X POST http://198.54.123.234:8400/tasks/execute \
  -H "Content-Type: application/json" \
  -d '[{
    "task_id": "task-'$(date +%s)'",
    "title": "TITLE",
    "description": "DESCRIPTION",
    "priority": "high"
  }]'
```

### Deploy Code
```bash
rsync -av /path/to/code root@198.54.123.234:/opt/fpai/service/
ssh root@198.54.123.234 'systemctl restart service'
```

### Check Ollama
```bash
ssh root@198.54.123.234 'ollama list'
ssh root@198.54.123.234 'ollama ps'
```

---

## üìÇ DOCUMENTATION LOCATIONS

**Main Docs:**
- `~/Development/SERVICES/FULL_SOVEREIGNTY_ACHIEVED.md` - Complete overview
- `~/Development/SERVICES/OPTIMIZATION_STRATEGY_COMPLETE.md` - 3-phase plan
- `~/Development/SERVICES/QUICK_START_GUIDE.md` - All commands

**Session Docs:**
- `~/Development/docs/sessions/SESSION_HANDOFFS/2025-11-15_SOVEREIGNTY_COMPLETE.md` - Last session
- `~/Development/docs/sessions/UNIFIED_KNOWLEDGE.json` - All accumulated knowledge

---

## üéØ CURRENT FOCUS (What We're Working On)

**Phase:** Optimization
**Goal:** $0 AI costs ‚Üí Maximum automation ‚Üí Revenue generation
**Next Steps:**
1. Deploy dashboard (high priority)
2. Migrate Claude workflows
3. Activate revenue streams

---

## üí∞ FINANCIAL TARGETS

**Costs:**
- Current AI: $0/month ‚úÖ
- Target AI: $0/month ‚úÖ
- Infrastructure: ~$100/month

**Revenue:**
- Current: $0/month
- Target: $20,000/month
- Margin: 95%+

**Revenue Streams:**
1. I MATCH (20% commissions) - $10K/month potential
2. AI Service Building ($500-2.5K each) - $5K/month potential
3. White-Label Deployments ($5K + $500/month) - $5K/month potential

---

## üß† TECHNICAL PATTERNS (How We Do Things)

### Deployment Pattern
```bash
# 1. Sync code
rsync -av local/ root@IP:/remote/

# 2. Restart service
ssh root@IP 'pkill -f service && cd /path && nohup start &'

# 3. Verify
curl http://IP:PORT/health
```

### API Task Pattern
```json
{
  "task_id": "unique-id",
  "title": "Short title",
  "description": "Detailed description",
  "priority": "high|medium|low"
}
```

### Common Blockers
- **LiteLLM required** for CrewAI + Ollama
- **First run slow** (3-4 min) - this is normal
- **Cache starts at 0%** - builds over time
- **Service needs restart** after code changes

---

## üéØ WHAT TO DO WHEN USER SAYS...

**"Build X"**
‚Üí Check if X already exists first (check /opt/fpai/, docs, pending work)

**"Why is this slow?"**
‚Üí First run? Expected (3-4 min). Subsequent? Should be 1-2 min. Cache building.

**"Can we use Claude/GPT?"**
‚Üí We're sovereign. Use local agents instead. Cost: $0.

**"What should we do next?"**
‚Üí Check pending work section above. Don't ask, just execute.

**"Is the system working?"**
‚Üí Run status commands first, then report actual status.

---

## üö® CRITICAL: READ THIS EVERY SESSION START

1. ‚úÖ Load this file (`~/.claude-context/SESSION_CONTEXT.md`)
2. ‚úÖ Check pending work (don't ask what to do)
3. ‚úÖ Verify system status (run health checks)
4. ‚úÖ Use sovereign agents (not paid APIs)
5. ‚úÖ Continue from where last session left off

---

**This context file = Everything you need to know.**
**Read it. Don't ask about things already decided.**
**Check what exists before building.**
**Use $0 agents, not paid APIs.**

üåê‚ö°üíé
