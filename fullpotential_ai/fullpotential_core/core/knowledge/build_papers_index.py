#!/usr/bin/env python3
"""
Scan the workspace for `papers` directories and build a markdown index.

The script intentionally keeps dependencies light so it can run anywhere the
repo is cloned. It inspects text files for philosophical keywords so M006 and
related missions can quickly find source material.
"""
from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Iterable, List

WORKSPACE_ROOT = Path(__file__).resolve().parents[3]
OUTPUT_PATH = Path(__file__).with_name("PAPERS_INDEX.md")
SCRIPT_NAME = Path(__file__).name
KEYWORDS = ["consciousism", "consciousness", "paradigm", "extractive", "regenerative"]
TEXT_EXTENSIONS = {
    ".md",
    ".txt",
    ".json",
    ".yaml",
    ".yml",
    ".py",
    ".sh",
    ".mdx",
    ".tex",
    ".rst",
}


@dataclass
class PaperEntry:
    relative_path: Path
    extension: str
    size_kb: float
    keywords: List[str]

    def to_row(self) -> str:
        keyword_text = ", ".join(self.keywords) if self.keywords else "â€“"
        return f"| `{self.relative_path}` | `{self.extension}` | {self.size_kb:>7.1f} | {keyword_text} |"


def discover_paper_dirs(root: Path) -> List[Path]:
    return sorted({p for p in root.rglob("papers") if p.is_dir()})


def detect_keywords(path: Path) -> List[str]:
    if path.suffix.lower() not in TEXT_EXTENSIONS:
        return []
    try:
        text = path.read_text(errors="ignore")
    except Exception:
        return []
    lowered = text.lower()
    return [kw for kw in KEYWORDS if kw in lowered]


def build_entries(directories: Iterable[Path]) -> List[PaperEntry]:
    entries: List[PaperEntry] = []
    for directory in directories:
        for file_path in sorted(directory.rglob("*")):
            if not file_path.is_file():
                continue
            rel_path = file_path.relative_to(WORKSPACE_ROOT)
            size_kb = round(file_path.stat().st_size / 1024, 1)
            keywords = detect_keywords(file_path)
            entries.append(
                PaperEntry(
                    relative_path=rel_path,
                    extension=file_path.suffix.lower() or "n/a",
                    size_kb=size_kb,
                    keywords=keywords,
                )
            )
    return sorted(entries, key=lambda entry: entry.relative_path.as_posix())


def render_markdown(directories: List[Path], entries: List[PaperEntry]) -> str:
    header = [
        "# Papers Index",
        "",
        f"_Generated by `{SCRIPT_NAME}`. Scan roots: {len(directories)} directories, {len(entries)} files._",
        "",
        "## Roots",
    ]
    header.extend([f"- `{d.relative_to(WORKSPACE_ROOT)}`" for d in directories] or ["- _No papers directories found_"])
    header.extend(
        [
            "",
            "## Files",
            "| File | Type | Size (KB) | Keywords |",
            "| --- | --- | ---: | --- |",
        ]
    )
    rows = [entry.to_row() for entry in entries] or ["| _No files found_ |  |  |  |"]
    return "\n".join(header + rows) + "\n"


def main() -> None:
    paper_dirs = discover_paper_dirs(WORKSPACE_ROOT)
    entries = build_entries(paper_dirs)
    OUTPUT_PATH.write_text(render_markdown(paper_dirs, entries))
    print(f"Wrote {OUTPUT_PATH} with {len(entries)} entries from {len(paper_dirs)} directories.")


if __name__ == "__main__":
    main()

