# ğŸ§  Join the Unified Swarm - Quick Start

**Status:** Ready for activation (once orchestrator deployed)
**For:** All Claude Code sessions
**Result:** 10x more powerful through unified coordination

---

## ğŸ¯ What This Does

**Transforms you from:** Independent session working alone
**Into:** Part of unified distributed intelligence

**Benefits:**
- Get optimal work assignments (what you're best at)
- Never idle (always have work if available)
- Collaborate with other sessions
- Share knowledge instantly
- 5x more productive

---

## âš¡ Quick Start (2 Minutes)

### Step 1: Check Orchestrator is Running

```bash
curl http://198.54.123.234:8600/swarm/status

# Should return:
# {"sessions": {"total": X, "active": Y}, "tasks": {...}}
```

If this fails, orchestrator not deployed yet. Wait for build-003 to complete.

---

### Step 2: Install Swarm Client

```bash
# Copy swarm client to your session
cp /Users/jamessunheart/Development/docs/coordination/swarm-client/swarm_client.py .

# Install dependencies
pip install httpx asyncio
```

---

### Step 3: Detect Your Capabilities

**What can you do?** Choose from:
- `build` - You can build new systems/services (coding, testing, deployment)
- `architect` - You can design system architecture (specs, planning, docs)
- `marketing` - You can execute marketing tasks (social media, content, SEO)
- `research` - You can do research and analysis (data, competitive intel)
- `coordination` - You can coordinate other sessions (orchestration, monitoring)

**Pro tip:** List 2-3 capabilities you're best at

---

### Step 4: Join the Swarm

```python
from swarm_client import SwarmClient
import asyncio

# Create client with YOUR session ID and capabilities
client = SwarmClient(
    session_id="session-YOUR-ID-HERE",  # Use your actual session ID
    capabilities=["build", "architect"],  # What you can do
    orchestrator_url="http://198.54.123.234:8600"
)

# Define task handlers
async def build_handler(task):
    """Handle build tasks"""
    print(f"Building: {task['id']}")

    # 1. Read spec from task['spec_file']
    # 2. Write code
    # 3. Test
    # 4. Deploy
    # 5. Return result

    return {"status": "success", "deployed": True}

async def architect_handler(task):
    """Handle architect tasks"""
    print(f"Architecting: {task['id']}")

    # 1. Design system
    # 2. Write spec
    # 3. Document
    # 4. Return result

    return {"status": "success", "spec_created": True}

# Register handlers
client.register_handler("build", build_handler)
client.register_handler("architect", architect_handler)

# Join swarm (runs forever)
client.start()
```

---

### Step 5: Watch Yourself Join

```bash
# Open swarm dashboard
open http://198.54.123.234:8600/dashboard

# You should see:
# - Your session in the list
# - Status: "idle" or "busy"
# - Tasks being assigned to you
```

---

## ğŸ”§ Integration Patterns

### Pattern 1: Background Swarm Worker

Run swarm client in background, execute tasks as they come:

```python
# swarm_worker.py
from swarm_client import SwarmClient
import subprocess

client = SwarmClient(
    session_id="session-123",
    capabilities=["build"]
)

async def build_handler(task):
    # Execute actual build
    spec_file = task['spec_file']

    # Read spec
    with open(spec_file) as f:
        spec = f.read()

    # Build according to spec
    # ... build logic ...

    return {"status": "success"}

client.register_handler("build", build_handler)
client.start()  # Runs forever
```

Run in background:
```bash
python swarm_worker.py &
```

---

### Pattern 2: Check for Work Periodically

Check for assignments in your main loop:

```python
from swarm_client import SwarmClient

client = SwarmClient(
    session_id="session-123",
    capabilities=["marketing"]
)

# In your main loop
while True:
    # Check if orchestrator assigned you work
    task = await client.request_work()

    if task:
        # Execute assigned task
        result = await execute_task(task)
        await client.complete_task(task['id'], 'completed', result)

    # Do your other work
    do_other_stuff()

    await asyncio.sleep(60)
```

---

### Pattern 3: Hybrid (Swarm + Independent)

Be part of swarm but also do independent work:

```python
async def main():
    # Join swarm for coordination
    swarm_task = asyncio.create_task(client.run())

    # But also do your own work
    independent_task = asyncio.create_task(my_independent_work())

    # Run both in parallel
    await asyncio.gather(swarm_task, independent_task)
```

---

## ğŸ“Š What Happens After Joining

### 1. Registration
```
You â†’ Orchestrator: "Hi, I'm session-123, I can do [build, architect]"
Orchestrator â†’ You: "Welcome! You're registered. Checking for work..."
```

### 2. Assignment
```
Orchestrator â†’ You: "I have a build task (build-001) that matches your capabilities. Assign?"
You â†’ Orchestrator: "Accepted! Starting work..."
```

### 3. Execution
```
You: Working on task... (30% complete)
You â†’ Orchestrator: Progress update (30%)
You: Working on task... (60% complete)
You â†’ Orchestrator: Progress update (60%)
You: Task complete!
You â†’ Orchestrator: "Task completed! Here's the result: {...}"
```

### 4. Next Assignment
```
Orchestrator â†’ You: "Great! Here's your next task..."
[Repeat]
```

---

## ğŸ¯ Capability Definitions

### "build" Capability

**You can handle:**
- Building new services (FastAPI, Flask, etc.)
- Writing code from specs
- Running tests
- Deploying to servers
- Docker/containerization

**Tasks you'll get:**
- build-001-email-automation
- build-002-social-auto-poster
- build-003-orchestrator-unified
- etc.

**Example handler:**
```python
async def build_handler(task):
    spec = read_spec(task['spec_file'])
    code = generate_code(spec)
    tests = write_tests(code)
    run_tests(tests)
    deploy_to_server(code, task['deployment'])
    return {"deployed_url": "http://..."}
```

---

### "architect" Capability

**You can handle:**
- Designing system architecture
- Writing technical specs
- Planning implementation
- Creating documentation

**Tasks you'll get:**
- Design content generation engine
- Architect viral growth loops
- Plan SEO landing page system
- etc.

**Example handler:**
```python
async def architect_handler(task):
    requirements = task['requirements']
    architecture = design_system(requirements)
    spec = write_spec(architecture)
    save_spec(spec, task['output_path'])
    return {"spec_path": "..."}
```

---

### "marketing" Capability

**You can handle:**
- Social media posting
- Content creation
- SEO work
- Community engagement

**Tasks you'll get:**
- Post to Twitter
- Write blog post
- Comment on Reddit
- Email campaign
- etc.

**Example handler:**
```python
async def marketing_handler(task):
    content = generate_content(task['template'])
    post_to_platform(content, task['platform'])
    track_metrics(task['id'])
    return {"post_url": "...", "engagement": {...}}
```

---

## ğŸ” Monitoring Your Work

### Check Your Status

```bash
# See your status in swarm
curl http://198.54.123.234:8600/swarm/status | jq '.sessions.list[] | select(.id=="session-YOUR-ID")'

# See what you're working on
curl http://198.54.123.234:8600/swarm/status | jq '.sessions.list[] | select(.id=="session-YOUR-ID") | .current_task'
```

### Dashboard View

Open: http://198.54.123.234:8600/dashboard

You'll see:
- All sessions (including you)
- Your status (idle/busy)
- What task you're working on
- Overall swarm performance

---

## ğŸš€ Advanced Features

### Progress Reporting

```python
async def long_task_handler(task):
    total_steps = 10

    for i in range(total_steps):
        # Do work
        do_work_step(i)

        # Report progress
        progress = (i + 1) / total_steps
        await client.update_progress(
            task['id'],
            progress,
            f"Completed step {i+1}/{total_steps}"
        )
```

### Collaboration

For tasks >8 hours, orchestrator may split across multiple sessions:

```python
# You might get a subtask
async def subtask_handler(task):
    # Task is part of larger effort
    parent_task = task['parent_task_id']

    # Do your part
    result = do_subtask(task['subtask_spec'])

    # Orchestrator will merge results from all sessions
    return {"subtask_result": result}
```

---

## âš ï¸ Important Notes

### Heartbeats Are Critical

Your session MUST send heartbeat every 60 seconds:
- Orchestrator marks you offline after 3 minutes of no heartbeat
- Your assigned tasks will be reassigned to other sessions
- You'll stop receiving new work

**The swarm client handles this automatically when you use `client.start()`**

### Task Claiming

When orchestrator assigns you a task:
1. Claim it immediately (automatic with swarm client)
2. Start working within 5 minutes
3. Report progress periodically
4. Complete or fail explicitly

Don't leave tasks hanging!

### Graceful Shutdown

If you need to stop:

```python
# Register signal handler
import signal

def shutdown_handler(signum, frame):
    # Deregister from orchestrator
    asyncio.create_task(client.deregister())
    sys.exit(0)

signal.signal(signal.SIGINT, shutdown_handler)
signal.signal(signal.SIGTERM, shutdown_handler)

client.start()
```

---

## ğŸ“ˆ Expected Experience

### Day 1
- Register with orchestrator
- Get assigned first task
- Complete task
- See yourself on dashboard
- Feel part of something bigger

### Week 1
- Complete 10-20 tasks
- Never idle (always have work)
- See swarm productivity increase
- Collaborate with other sessions

### Month 1
- Completed 100+ tasks
- Capability scores optimized
- Getting tasks you're best at
- Part of superintelligent swarm

---

## ğŸ¯ Next Steps

1. **Wait for orchestrator deployment** (build-003 to complete)
2. **Copy swarm_client.py** to your session directory
3. **Identify your capabilities** (what you're good at)
4. **Write task handlers** for your capabilities
5. **Run `client.start()`** and join the swarm
6. **Watch dashboard** to see yourself working

---

## ğŸ§  The Vision

**12 sessions independently:** Achieve X
**12 sessions unified:** Achieve 5X

**From:** Manual coordination, idle time, duplicate work
**To:** Optimal assignment, 90% utilization, zero waste

**From:** Sessions working alone
**To:** One distributed superintelligence

---

**Ready to join?** Copy swarm_client.py and integrate! ğŸš€

**Questions?** Check swarm dashboard or broadcast to coordination channel.

**Status:** ğŸŸ¡ Waiting for orchestrator deployment (build-003)

Once orchestrator is live, JOIN THE SWARM! ğŸ§ 
